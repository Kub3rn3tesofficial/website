---
title: बड़े क्लस्टर्ज़ के लिए विचार
weight: 20
---

एक क्लस्टर {{< glossary_tooltip text="नोड्स" term_id="node" >}} (भौतिक या वर्चुअल मशीन) का एक सेट है जो कुबेरनेट्स एजेंटों को चला रहा है, जिसे {{< glossary_tooltip text="कण्ट्रोल प्लेन" term_id="control-plane" >}} द्वारा प्रबंधित किया जाता है|
कुबेरनेट्स {{< param "version" >}} 5000 नोड्स तक क्लस्टर का समर्थन करता है| अधिक विशेष रूप से, कुबेरनेट्स को ऐसे कॉन्फ़िगरेशन को समायोजित करने के लिए डिज़ाइन किया गया है जो निम्नलिखित *सभी* मानदंडों को पूरा करते हैं: 

* प्रति नोड 110 पॉड से अधिक नहीं
* 5000 से अधिक नोड्स नहीं
* कुल पॉड्स 150000 से अधिक नहीं
* 300000 से अधिक कुल कंटेनर नहीं 

आप नोड्स जोड़कर या हटाकर अपने क्लस्टर को स्केल कर सकते हैं। आपके ऐसा करने का तरीका इस बात पर निर्भर करता है कि आपका क्लस्टर कैसे डिप्लॉय किया गया है|

## क्लाउड प्रदाता संसाधन कोटा

कई नोड्स के साथ क्लस्टर बनाते समय, क्लाउड प्रदाता कोटा मुद्दों में भाग लेने से बचने के लिए, इस पर विचार करें:

* क्लाउड संसाधनों के लिए कोटा बढ़ाने का अनुरोध करना, जैसे: 
    * कंप्यूटर उदाहरण
    * CPU
    * स्टोरेज वॉल्यूम
    * उपयोग में आने वाले IP पते
    * पैकेट फ़िल्टरिंग नियम सेट
    * लोड बैलेंसरों की संख्या
    * नेटवर्क सबनेट
    * लॉग स्ट्रीम
* बैचों के बीच एक ठहराव के साथ, बैचों में नए नोड्स लाने के लिए क्लस्टर स्केलिंग क्रियाओं को गेट करना, क्योंकि कुछ क्लाउड प्रदाता नए इंस्टेंस के निर्माण को सीमित करते हैं|

## कण्ट्रोल प्लेन अवयव 

एक बड़े क्लस्टर के लिए, आपको पर्याप्त गणना और अन्य संसाधनों के साथ एक कण्ट्रोल प्लेन की आवश्यकता होती है|

आम तौर पर आप प्रति विफलता क्षेत्र में एक या दो कण्ट्रोल प्लेन उदाहरण चलाएंगे, उन उदाहरणों को लंबवत स्केलिंग और फिर (vertical) स्केलिंग क्षैतिज रूप से स्केलिंग गिरने के बिंदु तक पहुंचने के बाद|

दोष-सहिष्णुता प्रदान करने के लिए आपको प्रति विफलता क्षेत्र में कम से कम एक उदाहरण चलाना चाहिए। कुबेरनेट्स नोड्स स्वचालित रूप से कण्ट्रोल प्लेन के समापन बिंदुओं की ओर ट्रैफ़िक नहीं चलाते हैं जो समान विफलता क्षेत्र में हैं; हालांकि, ऐसा करने के लिए आपके क्लाउड प्रदाता के पास अपना तंत्र हो सकता है|

उदाहरण के लिए, एक प्रबंधित लोड बैलेंसर का उपयोग करके, आप लोड बैलेंसर को विफलता क्षेत्र _A_ में क्यूबलेट और पॉड्स से आने वाले ट्रैफ़िक को भेजने के लिए कॉन्फ़िगर करते हैं, और उस ट्रैफ़िक को केवल उस कंट्रोल प्लेन होस्ट को निर्देशित करते हैं जो क्षेत्र _A_ में भी हैं। यदि एक सिंगल कंट्रोल प्लेन होस्ट या एंडपॉइंट विफलता क्षेत्र _A_ ऑफ़लाइन हो जाता है, तो इसका मतलब है कि क्षेत्र _A_ में नोड्स के लिए सभी कंट्रोल-प्लेन ट्रैफ़िक अब ज़ोन के बीच भेजे जा रहे हैं। प्रत्येक ज़ोन में कई कंट्रोल प्लेन होस्ट चलाने से उस परिणाम की संभावना कम हो जाती है|

### etcd भंडारण 

बड़े क्लस्टर के प्रदर्शन को बेहतर बनाने के लिए, आप इवेंट ऑब्जेक्ट को एक अलग समर्पित etcd इंस्टेंस में स्टोर कर सकते हैं|

क्लस्टर बनाते समय, आप (कस्टम टूलिंग का उपयोग करके) कर सकते हैं: 

* अतिरिक्त etcd उदाहरण शुरू और कॉन्फ़िगर करें
* {{< glossary_tooltip term_id="kube-apiserver" text="API सर्वर" >}} को घटनाओं को संग्रहीत करने के लिए उपयोग करने के लिए कॉन्फ़िगर करें

देखें [कुबेरनेट्स के लिए ऑपरेटिंग etcd क्लस्टर](/docs/tasks/admin-cluster/configure-upgrad-etcd/) और
[kubeadm के साथ एक उच्च उपलब्धता आदि क्लस्टर स्थापित करें]
एक बड़े क्लस्टर के लिए etcd को कॉन्फ़िगर करने और प्रबंधित करने के विवरण के लिए|

## ऐडऑन संसाधन 

कुबेरनेट्स [संसाधन सीमा](/docs/concepts/configuration/manage-resources-containers/) मेमोरी लीक के प्रभाव को कम करने में मदद करता है और अन्य तरीकों से पॉड और कंटेनर अन्य घटकों पर प्रभाव डाल सकते हैं| ये संसाधन सीमाएं {{< glossary_tooltip text="ऐडऑन्स" term_id="addons" >}} संसाधनों पर वैसे ही लागू होती हैं जैसे वे एप्लिकेशन वर्कलोड पर लागू होती हैं|

उदाहरण के लिए, आप लॉगिंग अवयव के लिए CPU और मेमोरी सीमा निर्धारित कर सकते हैं:

```yaml
  ...
  containers:
  - name: fluentd-cloud-logging
    image: fluent/fluentd-kubernetes-daemonset:v1
    resources:
      limits:
        cpu: 100m
        memory: 200Mi
```

ऐडऑन्स की डिफ़ॉल्ट सीमाएँ आमतौर पर छोटे या मध्यम कुबेरनेट्स क्लस्टर पर प्रत्येक एडऑन को चलाने के अनुभव से एकत्र किए गए डेटा पर आधारित होती हैं। बड़े क्लस्टर पर चलते समय, ऐडऑन अक्सर अपनी डिफ़ॉल्ट सीमा से अधिक कुछ संसाधनों का उपभोग करते हैं। यदि इन मानों को समायोजित किए बिना एक बड़ा क्लस्टर डिप्लॉय किया जाता है, तो एडऑन लगातार मारे जा सकते हैं क्योंकि वे स्मृति सीमा को मारते रहते हैं। वैकल्पिक रूप से, एडऑन चल सकता है लेकिन CPU समय स्लाइस प्रतिबंधों के कारण खराब प्रदर्शन के साथ|

क्लस्टर एडऑन संसाधन समस्याओं से बचने के लिए, कई नोड्स के साथ क्लस्टर बनाते समय, निम्नलिखित पर विचार करें: 

* कुछ ऐडऑन्स लंबवत रूप से स्केल करते हैं - क्लस्टर के लिए एडऑन की एक प्रतिकृति है या संपूर्ण विफलता क्षेत्र की सेवा कर रहा है। इन ऐडऑन्स के लिए, जैसे-जैसे आप अपने क्लस्टर का विस्तार करते हैं, अनुरोध और सीमाएँ बढ़ाते जाएँ|
* कई ऐडऑन्स क्षैतिज रूप से स्केल करते हैं - आप अधिक पॉड्स चलाकर क्षमता जोड़ते हैं - लेकिन एक बहुत बड़े क्लस्टर के साथ आपको CPU या स्मृति की सीमा को थोड़ा बढ़ाने की भी आवश्यकता हो सकती है। अनुरोधों और सीमाओं के लिए सुझाए गए आंकड़े प्रदान करने के लिए VerticalPodAutoscaler _recommender_ मोड में चल सकता है|
* कुछ ऐडऑन एक प्रति नोड के रूप में चलते हैं, जो एक {{< glossary_tooltip text="डेमनसेट(DaemonSet)" term_id="daemonset" >}} द्वारा नियंत्रित होते हैं: उदाहरण के लिए, एक नोड-स्तरीय लॉग एग्रीगेटर। क्षैतिज रूप से स्केल किए गए ऐडऑन के मामले के समान, आपको सीपीयू या मेमोरी सीमा को थोड़ा बढ़ाने की भी आवश्यकता हो सकती है|

## {{% heading "whatsnext" %}}

`VerticalPodAutoscaler` एक कस्टम संसाधन है जिसे आप पॉड के लिए संसाधन अनुरोधों और सीमाओं को प्रबंधित करने में मदद करने के लिए अपने क्लस्टर में डिप्लॉय कर सकते हैं|
[वर्टिकल पॉड ऑटोस्केलर](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler#readme) पर जाएं `VerticalPodAutoscaler` के बारे में अधिक जानने के लिए और क्लस्टर-महत्वपूर्ण ऐडऑन्स सहित क्लस्टर अवयव को स्केल करने के लिए आप इसका उपयोग कैसे कर सकते हैं।

[क्लस्टर ऑटोस्केलर](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler#readme)
कई क्लाउड प्रदाताओं के साथ एकीकृत होता है, जिससे आपको संसाधन की मांग के स्तर के लिए सही संख्या में नोड्स चलाने में मदद मिलती है, अपने क्लस्टर में|

[एडऑन रिसाइज़र](https://github.com/kubernetes/autoscaler/tree/master/addon-resizer#readme)
आपके क्लस्टर के पैमाने में बदलाव के साथ ऐडऑन का आकार बदलने में आपकी मदद करता है|