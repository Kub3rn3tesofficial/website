---
title: 障害
content_type: コンセプト
weight: 60
---

<!-- 概要 -->
このガイドは、高可用性のあるアプリケーションを構築したいアプリケーションオーナーおよびそれに伴い、Pod に発生する可能性のある障害の種類を理解する必要がある方々のためのものです。

また、クラスタ管理者はクラスタの自動化されたアクション、例えばクラスタのアップグレードや自動スケーリングなどを実行したい場合にも役立ちます。

<!-- 本文 -->

## 自発的および非自発的な障害

Pod は、誰か（人間またはコントローラ）が破壊するか、避けられないハードウェアまたはシステムソフトウェアのエラーが発生するまで消失しません。

これらの避けられないケースをアプリケーションの「非自発的障害」と呼びます。例は以下の通りです。

- ノードのバックエンドの物理マシンのハードウェア障害
- クラスタ管理者が誤って VM（インスタンス）を削除する
- クラウドプロバイダまたはハイパーバイザの障害により VM が消失
- カーネルパニック
- クラスタネットワークの分割によりノードがクラスタから消失
- ノードが [リソース不足](/docs/concepts/scheduling-eviction/node-pressure-eviction/) により Pod を追い出す

リソース不足の条件を除き、これらの状況はほとんどのユーザーにとって馴染みのあるものです。これらは Kubernetes 固有のものではありません。

その他の場合を「自発的な障害」と呼びます。これにはアプリケーションオーナーによって起動されるアクションと、クラスタ管理者によって起動されるアクションの両方が含まれます。典型的なアプリケーションオーナーのアクションには以下のものがあります。

- デプロイメントまたはその他のコントローラを削除する
- デプロイメントの Pod テンプレートを更新して再起動を引き起こす
- Pod を直接削除する（例：誤って削除）

クラスタ管理者のアクションには以下のものがあります。

- [ノードのドレイン](/docs/tasks/administer-cluster/safely-drain-node/) を修復またはアップグレードのために実行する
- クラスタをスケーリングダウンするためにクラスタからノードをドレインする（[クラスタオートスケーリングについて詳しくはこちら](https://github.com/kubernetes/autoscaler/#readme)）
- 何か他のものをノードに収めるために Pod をノードから削除する

これらのアクションは、クラスタ管理者自身によって直接実行されるか、クラスタ管理者によって実行される自動化、またはクラスタホスティングプロバイダによって実行される可能性があります。

クラスタの管理者に問い合わせるか、クラウドプロバイダまたはディストリビューションのドキュメンテーションを参照して、クラスタで自発的な障害が有効になっているかどうかを確認してください。有効なものがない場合は、Pod Disruption Budgets の作成をスキップできます。

{{< caution >}}
自発的な障害はすべてが Pod Disruption Budgets によって制約されるわけではありません。例えば、デプロイメントや Pod の削除は Pod Disruption Budgets をバイパスします。
{{< /caution >}}

## 障害への対処方法

以下は、非自発的な障害を緩和するいくつかの方法です。

- Pod が必要なリソースを要求することを確認する[/docs/tasks/configure-pod-container/assign-memory-resource](/docs/tasks/configure-pod-container/assign-memory-resource)。
- 必要に応じてアプリケーションをレプリケートする（レプリケーションされた[stateless](/docs/tasks/run-application/run-stateless-application-deployment/) および[stateful](/docs/tasks/run-application/run-replicated-stateful-application/) アプリケーションの実行について学ぶ）。
- レプリケートされたアプリケーションを実行する際のさらなる高可用性のために、アプリケーションをラック（[anti-affinity](/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity) を使用）またはゾーン（[マルチゾーンクラスタを使用する場合](/docs/setup/multiple-zones)）に分散させる。

自発的な障害の頻度は異なります。基本的な Kubernetes クラスタでは、自動的な自発的な障害はありません（ユーザーによってトリガされるもののみ）。ただし、クラスタ管理者またはホスティングプロバイダは、自発的な障害を引き起こすいくつかの追加のサービスを実行する可能性があります。例えば、ノードソフトウェアのアップデートの展開は、自発的な障害を引き起こす可能性があります。また、クラスタ（ノード）のオートスケーリングの一部の実装は、ノードのデフラグメンテーションとコンパクト化のために自発的な障害を引き起こす可能性があります。クラスタの管理者またはホスティングプロバイダは、期待される自発的な障害のレベルについてドキュメント化するはずです。特定の構成オプション、例えば [PriorityClasses の使用](/docs/concepts/scheduling-eviction/pod-priority-preemption/) は、Pod の仕様で自発的な（および非自発的な）障害を引き起こす可能性があります。


## Pod 障害予算

{{< feature-state for_k8s_version="v1.21" state="stable" >}}

Kubernetes は、頻繁な自発的な障害が発生する場合でも、高可用性のあるアプリケーションを実行するのに役立つ機能を提供します。

アプリケーションオーナーとして、各アプリケーションに対して PodDisruptionBudget（PDB）を作成できます。PDB は、自発的な障害による同時に停止するレプリケーションアプリケーションの数を制限します。例えば、クオーラムベースのアプリケーションでは、クオーラムに必要なレプリカ数を常に保つ必要があります。ウェブフロントエンドは、ロードを提供するレプリカの数が一定の割合を下回らないようにするかもしれません。

クラスタマネージャやホスティングプロバイダは、PodDisruptionBudgets を尊重するために、Pod またはデプロイメントを直接削除する代わりに [Eviction API](/docs/tasks/administer-cluster/safely-drain-node/#eviction-api) を呼び出すツールを使用すべきです。

例えば、`kubectl drain` サブコマンドを使用すると、ノードをサービスから外れた状態にすることができます。`kubectl drain` を実行すると、ツールは対象となるノードのすべての Pod を追い出そうとします。`kubectl` があなたの代わりに提出する追い出しリクエストは一時的に拒否される場合がありますので、ツールはすべての失敗したリクエストを定期的にリトライし、対象ノード上のすべての Pod が終了するか、設定可能なタイムアウトが到達するまでリトライします。

PDB は、アプリケーションが許容できるレプリカの数を指定し、そのアプリケーションが意図している数からの相対的なものです。例えば、`.spec.replicas: 5` を持つ Deployment は、任意の時点で 5 つの Pod が存在する必要があります。その PDB が同時に 4 つ存在することを許容する場合、Eviction API は一度に 1 つの Pod を自発的に障害を引き起こすことを許可します（ただし 2 つの Pod を許可しません）。

アプリケーションを構成するポッドグループは、アプリケーションのコントローラ（デプロイメント、ステートフルセットなど）と同じラベルセレクタを使用して指定されます。

「意図される」ポッドの数は、それらのポッドを管理するワークロードリソース（Deployment、StatefulSet など）の `.spec.replicas` から計算されます。制御プレーンは、Pod の `.metadata.ownerReferences` を調べることで所有するワークロードリソースを見つけます。

[PDB によって予防できない障害](#自発的および非自発的な障害) も予算にカウントされます。

アプリケーションのローリングアップグレードによる削除または利用できないポッドは、障害予算にカウントされますが、ワークロードリソース（Deployment および StatefulSet など）は、ローリングアップグレードを実行する際の障害予算に制限されません。代わりに、アプリケーションのアップデート中の障害の処理は、特定のワークロードリソースの仕様で設定されます。

ノードのドレイン中に不正なアプリケーションの追放をサポートするために、PodDisruptionBudgets に `AlwaysAllow` [不健全なポッドの追放ポリシー](/docs/tasks/run-application/configure-pdb/#unhealthy-pod-eviction-policy) を設定することをお勧めします。デフォルトの動作は、ドレインが進行する前にアプリケーションのポッドが[健全になる](/docs/tasks/run-application/configure-pdb/#healthiness-of-a-pod)のを待つことです。

Pod が eviction API を使用して追放される際、その Pod は[適切に終了](/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination)され、その [PodSpec](/docs/reference/generated/kubernetes-api/{{< param "version" >}}/#podspec-v1-core) の `terminationGracePeriodSeconds` 設定が尊重されます。

## PodDisruptionBudget の例 {#pdb-example}

3 つのノード、`node-1` から `node-3` からなるクラスタを考えてみましょう。
クラスタはいくつかのアプリケーションを実行しています。そのうちの1つに最初に `pod-a`、`pod-b`、`pod-c` と呼ばれる 3 つのレプリカがあります。別の関連のないポッドで、PDB がない `pod-x` という名前のものも表示されています。最初は、ポッドは次のように配置されます。

|       node-1         |       node-2        |       node-3       |
|:--------------------:|:-------------------:|:------------------:|
| pod-a  *利用可能*   | pod-b *利用可能*   | pod-c *利用可能*  |
| pod-x  *利用可能*   |                     |                    |

3 つのポッドはすべてデプロイメントの一部であり、PDB は常に 3 つのうち 2 つのポッドが常に利用可能であることを要求しています。

例えば、クラスタ管理者がバグを修正するために新しいカーネルバージョンにリブートする必要があるとします。クラスタ管理者は、最初に `kubectl drain` コマンドを使用して `node-1` をドレインしようとします。
そのツールは `pod-a` と `pod-x` を追い出そうとします。これはすぐに成功します。
両方のポッドは同時に `terminating` 状態になります。
これにより、クラスタは次のような状態になります。

|   node-1 *ドレイン中*  |       node-2        |       node-3       |
|:--------------------:|:-------------------:|:------------------:|
| pod-a  *終了中* | pod-b *利用可能*   | pod-c *利用可能*  |
| pod-x  *終了中* |                     |                    |

デプロイメントは、ポッドが終了するのを検出するため、`pod-d` という置き換えを作成します。`node-1` がコードされているため、別のノードに着地します。また、`pod-x` の代わりに `pod-y` という置き換えも作成されています。

（注：StatefulSet の場合、`pod-a` は `pod-0` のように呼ばれ、その代わりに完全に終了する必要があります。これは同じ `pod-0` と呼ばれ、異なる UID を持つ別の `pod-0` が作成されるまで、適用例にも適用されます。）

さて、クラスタは次のような状態になります。

|   node-1 *ドレイン中*  |       node-2        |       node-3       |
|:--------------------:|:-------------------:|:------------------:|
| pod-a  *終了中* | pod-b *利用可能*   | pod-c *利用可能*  |
| pod-x  *終了中* | pod-d *起動中*    | pod-y              |

いずれかのポイントで、ポッドが終了し、クラスタは次のような状態になります。

|    node-1 *ドレイン済*  |       node-2        |       node-3       |
|:--------------------:|:-------------------:|:------------------:|
| pod-d *実行中*    | pod-b *利用可能*   | pod-c *利用可能*  |
|                         | pod-y *実行中*   |                    |

それから、クラスタ管理者は `node-1` を再起動し、`pod-d` は自動的に別のノードに再スケジュールされます。

最終的に、クラスタは最初の状態に戻ります。

|       node-1         |       node-2        |       node-3       |
|:--------------------:|:-------------------:|:------------------:|
| pod-a  *利用可能*   | pod-b *利用可能*   | pod-c *利用可能*  |
| pod-x  *利用可能*   |                     |                    |

この例では、PDB が設定されているため、一貫した可用性が維持されます。同時に実行されるポッドの最大数が制御され、システム全体の安定性が向上します。

{{< note >}}
PDB を作成する際には、Pod がどのようなクラスタ内で実行されるか、どのようなサービスがあるかを考慮することが重要です。PDB の目標を達成するために、アプリケーション全体のレプリカ数や他の要因を考慮することも重要です。
{{< /note >}}
